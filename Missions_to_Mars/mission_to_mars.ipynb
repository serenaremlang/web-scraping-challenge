{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import pandas as pd\n",
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "import time\n",
    "from webdriver_manager.chrome import ChromeDriverManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NASA Mars News\n",
    "Scrape the Mars News Site and collect the latest News Title and Paragraph Text. Assign the text to variables that you can reference later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up url request\n",
    "url = \"https://redplanetscience.com\"\n",
    "response = requests.get(url)\n",
    "\n",
    "# Scrape page into Soup\n",
    "soup = bs(response.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the parent divs for all articles\n",
    "results = soup.find_all('div', class_='##')\n",
    "\n",
    "news_title = []\n",
    "news_p = []\n",
    "\n",
    "# loop over results to get article data\n",
    "for result in results:\n",
    "    # scrape the article header \n",
    "    title = result.find('h1', class_='article-item__headline').text\n",
    "    news_title.append(title)\n",
    "    \n",
    "    # scrape the article subheader\n",
    "    para = result.find('p', class_='article').text\n",
    "    news_p.append(para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(news_title) \n",
    "print(news_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JPL Mars Space Images - Featured Image\n",
    "- Visit the url for the Featured Space Image site here.\n",
    "- Use splinter to navigate the site and find the image url for the current Featured Mars Image and assign the url string to a variable called featured_image_url.\n",
    "- Make sure to find the image url to the full size .jpg image.\n",
    "- Make sure to save a complete url string for this image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Splinter\n",
    "executable_path = {'executable_path': ChromeDriverManager().install()}\n",
    "browser = Browser('chrome', **executable_path, headless=False)\n",
    "\n",
    "# Visit spaceimages-mars.com\n",
    "url = \"https://spaceimages-mars.com\"\n",
    "browser.visit(url)\n",
    "\n",
    "time.sleep(1)\n",
    "\n",
    "# Scrape page into Soup\n",
    "html = browser.html\n",
    "soup = bs(html, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featured_image_url = soup.find('img')[0]['src']\n",
    "full_featured_image_url = url + featured_image_url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mars Facts\n",
    "\n",
    "- Visit the Mars Facts webpage here and use Pandas to scrape the table containing facts about the planet including Diameter, Mass, etc.\n",
    "- Use Pandas to convert the data to a HTML table string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://galaxyfacts-mars.com'\n",
    "df = pd.read_html(url)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to html table\n",
    "df.to_html('/resources/Mars_facts.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mars Hemispheres\n",
    "\n",
    "- Visit the astrogeology site here to obtain high resolution images for each of Mar's hemispheres.\n",
    "- You will need to click each of the links to the hemispheres in order to find the image url to the full resolution image.\n",
    "- Save both the image url string for the full resolution hemisphere image, and the Hemisphere title containing the hemisphere name. Use a Python dictionary to store the data using the keys img_url and title.\n",
    "- Append the dictionary with the image url string and the hemisphere title to a list. This list will contain one dictionary for each hemisphere. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Splinter\n",
    "executable_path = {'executable_path': ChromeDriverManager().install()}\n",
    "browser = Browser('chrome', **executable_path, headless=False)\n",
    "\n",
    "# Visit spaceimages-mars.com\n",
    "url = 'https://marshemispheres.com'\n",
    "browser.visit(url)\n",
    "\n",
    "time.sleep(1)\n",
    "\n",
    "# Scrape page into Soup\n",
    "html = browser.html\n",
    "soup = bs(html, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hemisphere dictionary\n",
    "hemisphere_image_urls = [\n",
    "    {\"title\": \"Valles Marineris Hemisphere\", \"img_url\": \"...\"},\n",
    "    {\"title\": \"Cerberus Hemisphere\", \"img_url\": \"...\"},\n",
    "    {\"title\": \"Schiaparelli Hemisphere\", \"img_url\": \"...\"},\n",
    "    {\"title\": \"Syrtis Major Hemisphere\", \"img_url\": \"...\"},\n",
    "]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d0dfd7268789880de84d768d68ff31902ba531fbeb8e3be281708f0089ada016"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 64-bit ('PythonData': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
